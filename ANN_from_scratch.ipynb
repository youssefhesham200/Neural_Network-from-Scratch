{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa13d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imported (just for import dataset) \n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a415d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f11e78f7a30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train,y_train) , (x_test, y_test) = keras.datasets.mnist.load_data() \n",
    "x_train = x_train[:10000] / 255\n",
    "y_train = y_train[:10000]\n",
    "x_test = x_test[:1000] / 255\n",
    "y_test = y_test[:1000]\n",
    "\n",
    "plt.imshow(x_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d702060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(grid):\n",
    "    if np.all((grid == 0)):\n",
    "        return (3.5,3.5)\n",
    "    return ndimage.measurements.center_of_mass(grid)\n",
    "\n",
    "def crop_feature(test_image, blocks):\n",
    "    rows , cols = int(test_image.shape[0] / blocks), int(test_image.shape[1] / blocks)\n",
    "    vector = list()\n",
    "    k,f = cols,0\n",
    "    for i in range(blocks):\n",
    "        c,z = rows,0\n",
    "        for r in range(blocks):\n",
    "                window = test_image[f:k,z:c]\n",
    "                c += rows\n",
    "                z += rows\n",
    "                x,y = centroid(window)\n",
    "                vector.extend([x,y])\n",
    "        k += cols\n",
    "        f += cols\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f89194",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = list() \n",
    "x_test1  = list() \n",
    "\n",
    "for i in x_train:\n",
    "    x_train1.append(crop_feature(i,4))\n",
    "\n",
    "for i in x_test:\n",
    "    x_test1.append(crop_feature(i,4))\n",
    "\n",
    "    \n",
    "# normalize input values from 0 -> 1 \n",
    "\n",
    "x_train1 = np.array(x_train1)\n",
    "x_test1 = np.array(x_test1)\n",
    "x_train1 = x_train1.transpose() / 7\n",
    "x_test1  = x_test1.transpose() / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d418da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHot encoding for y train values\n",
    "\n",
    "y_train = np.array(pd.get_dummies(y_train)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c899478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN():\n",
    "    \n",
    "    def __init__(self):   \n",
    "        pass\n",
    "    \n",
    "    def argmax(self, data):\n",
    "        l = list(data)\n",
    "        maxl = max(l)\n",
    "        best = l.index(maxl)\n",
    "        return best\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return (1 / (1 + np.exp(-x)))  \n",
    "\n",
    "    \n",
    "    def initialize_parameters(self, n_x, n_h, n_y):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "        n_x -- size of the input layer\n",
    "        n_h -- size of the hidden layer\n",
    "        n_y -- size of the output layer\n",
    "\n",
    "        Returns:\n",
    "        params -- python dictionary containing your parameters:\n",
    "                        W1 -- weight matrix of shape (n_h, n_x)\n",
    "                        b1 -- bias vector of shape (n_h, 1)\n",
    "                        W2 -- weight matrix of shape (n_y, n_h)\n",
    "                        b2 -- bias vector of shape (n_y, 1)\n",
    "        \"\"\"    \n",
    "        np.random.seed(3)\n",
    "        W1 = np.random.randint(-2,2,size = (n_h, n_x)) \n",
    "        b1 = np.zeros((n_h,1))  \n",
    "        W2 = np.random.randint(-2,2,size = (n_y, n_h)) \n",
    "        b2 = np.zeros((n_y,1)) \n",
    "\n",
    "        parameters = {\"W1\": W1,\n",
    "                      \"b1\": b1,\n",
    "                      \"W2\": W2,\n",
    "                      \"b2\": b2}\n",
    "\n",
    "        return parameters\n",
    "\n",
    "\n",
    "    \n",
    "    def forward_propagation(self, X, parameters):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "        X -- input data of size (n_x, m)\n",
    "        parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "\n",
    "        Returns:\n",
    "        A2 -- The sigmoid output of the second activation\n",
    "        cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "        \"\"\"\n",
    "        W1 = parameters['W1']\n",
    "        W2 = parameters['W2']\n",
    "        b2 = parameters['b2']\n",
    "        b1 = parameters['b1']\n",
    "\n",
    "    \n",
    "        Z1 = np.dot(W1, X) + b1                  # sizes (100, 32) * (32,1) = (100, 1)\n",
    "        A1 = self.sigmoid(Z1)\n",
    "        Z2 = np.dot(W2, A1) + b2                 # sizes (10, 100) * (100, 1) = (10,1)\n",
    "        A2 = self.sigmoid(Z2)\n",
    "\n",
    "\n",
    "        cache = {\"Z1\": Z1,\n",
    "                 \"A1\": A1,\n",
    "                 \"Z2\": Z2,\n",
    "                 \"A2\": A2}\n",
    "\n",
    "        return A2, cache                 \n",
    "\n",
    "    \n",
    "    def backward_propagation(self, parameters, cache, X, Y):\n",
    "        \"\"\"\n",
    "\n",
    "        Arguments:\n",
    "        parameters -- python dictionary containing our parameters \n",
    "        cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "        X -- input data of shape (2, number of examples)\n",
    "        Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "        \n",
    "        Returns:\n",
    "        grads -- python dictionary containing your gradients with respect to different parameters\n",
    "        \"\"\"\n",
    "        m = X.shape[1]\n",
    "\n",
    "        W1 = parameters['W1']\n",
    "        W2 = parameters['W2']\n",
    "        \n",
    "        A1 = cache['A1']\n",
    "        A2 = cache['A2']\n",
    "\n",
    "        dZ2 = (Y-A2)* (A2 * (1-A2))                           # size (10,1)                    \n",
    "        dW2 = (1/m) * np.dot(dZ2, A1.transpose())             # (10,1) * (1,100) = (10,100)\n",
    "        db2 = (1/m) * np.sum(dZ2, axis = 1, keepdims=True)           \n",
    "        dZ1 = np.dot(W2.transpose(),dZ2) * (A1 * (1-A1))  \n",
    "        dW1 = (1/m) * np.dot(dZ1, X.transpose())\n",
    "        db1 = (1/m) * np.sum(dZ1, axis = 1, keepdims=True)\n",
    "\n",
    "        grads = {\"dW1\": dW1,\n",
    "                 \"db1\": db1,\n",
    "                 \"dW2\": dW2,\n",
    "                 \"db2\": db2}\n",
    "\n",
    "        return grads\n",
    "    \n",
    "\n",
    "    \n",
    "    def update_parameters(self, parameters, grads, learning_rate = 0.5):\n",
    "        \"\"\"\n",
    "\n",
    "        Arguments:\n",
    "        parameters -- python dictionary containing your parameters \n",
    "        grads -- python dictionary containing your gradients \n",
    "\n",
    "        Returns:\n",
    "        parameters -- python dictionary containing your updated parameters \n",
    "        \"\"\"\n",
    "    \n",
    "        W1 = parameters['W1'] \n",
    "        b1 = parameters['b1']\n",
    "        W2 = parameters['W2'] \n",
    "        b2 = parameters['b2'] \n",
    "        \n",
    "        dW1 = grads['dW1']\n",
    "        dW2 = grads['dW2']\n",
    "        db1 = grads['db1']\n",
    "        db2 = grads['db2']\n",
    "        \n",
    "\n",
    "        W1 = W1 + learning_rate * dW1\n",
    "        W2 = W2 + learning_rate * dW2\n",
    "        b1 = b1 + learning_rate * db1\n",
    "        b2 = b2 + learning_rate * db2\n",
    "\n",
    "\n",
    "        parameters = {\"W1\": W1,\n",
    "                      \"b1\": b1,\n",
    "                      \"W2\": W2,\n",
    "                      \"b2\": b2}\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    def fit(self, X, Y, n_h, epchos = 100, learning_rate=0.1):\n",
    "        \n",
    "        parameters = self.initialize_parameters(32,n_h,10)\n",
    "\n",
    "        for i in range(0, epchos):\n",
    "            for j in range(0, X.shape[1]):\n",
    "    \n",
    "                A2, cache = self.forward_propagation(X[:,j].reshape(X.shape[0],1), parameters)\n",
    "\n",
    "                grads = self.backward_propagation(parameters,cache, X[:,j].reshape(X.shape[0],1), Y[:,j].reshape(Y.shape[0],1))\n",
    "\n",
    "                parameters = self.update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "    def predict(self, X, parameters):\n",
    "        A2, cache = self.forward_propagation(X, parameters)\n",
    "        y_pred = list()\n",
    "        m = A2.shape[1]\n",
    "        for i in range(m):\n",
    "            y_pred.append(np.argmax(A2[:,i]))\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def accuracy(self, y_pred, y_test):\n",
    "        con = 0\n",
    "        for i,j in zip(y_pred, y_test):\n",
    "            if(i == j):\n",
    "               con += 1 \n",
    "        return (con / len(y_pred)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e684c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN()\n",
    "\n",
    "parameters = model.fit(x_train1, y_train, 100, 100, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca150108",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test1, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666d94af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
